[2025-12-05 10:17:06] [INFO] ================================================================================
[2025-12-05 10:17:06] [INFO] ЗАПУСК ОБУЧЕНИЯ МОДЕЛИ
[2025-12-05 10:17:06] [INFO] ================================================================================
[2025-12-05 10:17:06] [INFO] СИСТЕМНАЯ ИНФОРМАЦИЯ:
[2025-12-05 10:17:07] [INFO] CPU: 12 cores, Использование: 3.4%
RAM: Всего: 15.2GB, Используется: 63.0%, Свободно: 5.6GB
GPU: 1 устройств(а)
  GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU, Память: 6.0GB
[2025-12-05 10:17:07] [INFO] Начало: Загрузка данных
[2025-12-05 10:17:07] [INFO] Загружен датасет из data/processed
[2025-12-05 10:17:07] [INFO] Количество примеров: 50000
[2025-12-05 10:17:07] [INFO] Колонки датасета: ['input', 'target']
[2025-12-05 10:17:07] [INFO] Завершено: Загрузка данных | Затрачено времени: 0.05 секунд (0:00:00)
[2025-12-05 10:17:07] [INFO] Начало: Загрузка токенизатора
[2025-12-05 10:17:08] [INFO] Токенизатор загружен: google/flan-t5-small
[2025-12-05 10:17:08] [INFO] Размер словаря: 32100
[2025-12-05 10:17:08] [INFO] Завершено: Загрузка токенизатора | Затрачено времени: 0.97 секунд (0:00:00)
[2025-12-05 10:17:08] [INFO] Начало: Токенизация данных
[2025-12-05 10:17:08] [INFO] Токенизация завершена. Размер: 50000
[2025-12-05 10:17:08] [INFO] Завершено: Токенизация данных | Затрачено времени: 0.08 секунд (0:00:00)
[2025-12-05 10:17:08] [INFO] Начало: Загрузка модели
[2025-12-05 10:17:08] [INFO] Загрузка модели в 8-bit режиме...
[2025-12-05 10:17:10] [INFO] Модель подготовлена для k-bit обучения
[2025-12-05 10:17:10] [INFO] Завершено: Загрузка модели | Затрачено времени: 2.44 секунд (0:00:02)
[2025-12-05 10:17:10] [INFO] Начало: Настройка LoRA
[2025-12-05 10:17:10] [INFO] LoRA конфигурация применена
[2025-12-05 10:17:10] [INFO] Всего параметров: 79,123,840
[2025-12-05 10:17:10] [INFO] Обучаемых параметров (LoRA): 2,162,688 (2.73%)
[2025-12-05 10:17:10] [INFO] Завершено: Настройка LoRA | Затрачено времени: 0.11 секунд (0:00:00)
[2025-12-05 10:17:10] [INFO] ================================================================================
ПАРАМЕТРЫ ОБУЧЕНИЯ
================================================================================
Модель: google/flan-t5-small
Устройство: cuda
8-bit обучение: True
Размер батча: 8
Эпохи: 3
Learning rate: 0.0003
Макс. длина входных данных: 256
Макс. длина целевых данных: 128
Размер обучающего набора: 50000 примеров
Всего параметров модели: 79,123,840
Обучаемых параметров: 2,162,688 (2.73%)
Необучаемых параметров: 76,961,152
================================================================================
[2025-12-05 10:17:13] [INFO] ================================================================================
[2025-12-05 10:17:13] [INFO] НАЧАЛО ОБУЧЕНИЯ МОДЕЛИ
[2025-12-05 10:17:13] [INFO] ================================================================================
[2025-12-05 10:17:13] [INFO] Начало: Обучение модели
[2025-12-05 10:18:41] [INFO] Шаг 100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.032}
[2025-12-05 10:20:07] [INFO] Шаг 200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.064}
[2025-12-05 10:21:32] [INFO] Шаг 300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.096}
[2025-12-05 10:23:00] [INFO] Шаг 400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.128}
[2025-12-05 10:24:26] [INFO] Шаг 500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.16}
[2025-12-05 10:25:51] [INFO] Шаг 600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.192}
[2025-12-05 10:27:18] [INFO] Шаг 700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.224}
[2025-12-05 10:28:46] [INFO] Шаг 800: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.256}
[2025-12-05 10:30:14] [INFO] Шаг 900: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.288}
[2025-12-05 10:31:42] [INFO] Шаг 1000: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.32}
[2025-12-05 10:33:10] [INFO] Шаг 1100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.352}
[2025-12-05 10:34:39] [INFO] Шаг 1200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.384}
[2025-12-05 10:36:06] [INFO] Шаг 1300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.416}
[2025-12-05 10:37:31] [INFO] Шаг 1400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.448}
[2025-12-05 10:38:57] [INFO] Шаг 1500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.48}
[2025-12-05 10:40:25] [INFO] Шаг 1600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.512}
[2025-12-05 10:41:53] [INFO] Шаг 1700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.544}
[2025-12-05 10:43:21] [INFO] Шаг 1800: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.576}
[2025-12-05 10:44:49] [INFO] Шаг 1900: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.608}
[2025-12-05 10:46:18] [INFO] Шаг 2000: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.64}
[2025-12-05 10:47:46] [INFO] Шаг 2100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.672}
[2025-12-05 10:49:13] [INFO] Шаг 2200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.704}
[2025-12-05 10:50:42] [INFO] Шаг 2300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.736}
[2025-12-05 10:52:10] [INFO] Шаг 2400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.768}
[2025-12-05 10:53:38] [INFO] Шаг 2500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.8}
[2025-12-05 10:55:07] [INFO] Шаг 2600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.832}
[2025-12-05 10:56:34] [INFO] Шаг 2700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.864}
[2025-12-05 10:58:00] [INFO] Шаг 2800: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.896}
[2025-12-05 10:59:25] [INFO] Шаг 2900: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.928}
[2025-12-05 11:00:52] [INFO] Шаг 3000: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.96}
[2025-12-05 11:02:21] [INFO] Шаг 3100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.992}
[2025-12-05 11:02:43] [INFO] Завершена эпоха 1.0/3
[2025-12-05 11:02:43] [INFO] GPU 0 память: выделено 0.21GB, зарезервировано 0.76GB
[2025-12-05 11:02:43] [INFO] CPU использование: 18.4%, RAM использование: 62.1%
[2025-12-05 13:34:35] [INFO] Шаг 3125: {'eval_loss': nan, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 9111.6952, 'eval_samples_per_second': 5.487, 'eval_steps_per_second': 0.686, 'epoch': 1.0}
[2025-12-05 13:35:43] [INFO] Шаг 3200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.024}
[2025-12-05 13:37:12] [INFO] Шаг 3300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.056}
[2025-12-05 13:38:48] [INFO] Шаг 3400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.088}
[2025-12-05 13:40:22] [INFO] Шаг 3500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.12}
[2025-12-05 13:41:52] [INFO] Шаг 3600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.152}
[2025-12-05 13:43:22] [INFO] Шаг 3700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 1.184}
[2025-12-05 13:44:52] [INFO] Завершено: Обучение модели | Затрачено времени: 12459.51 секунд (3:27:39)
[2025-12-05 13:44:52] [INFO] Память GPU очищена
