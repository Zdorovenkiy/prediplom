[2025-12-05 04:31:16] [INFO] ================================================================================
[2025-12-05 04:31:16] [INFO] ЗАПУСК ОБУЧЕНИЯ МОДЕЛИ
[2025-12-05 04:31:16] [INFO] ================================================================================
[2025-12-05 04:31:16] [INFO] СИСТЕМНАЯ ИНФОРМАЦИЯ:
[2025-12-05 04:31:17] [INFO] CPU: 12 cores, Использование: 4.5%
RAM: Всего: 15.2GB, Используется: 64.0%, Свободно: 5.5GB
GPU: 1 устройств(а)
  GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU, Память: 6.0GB
[2025-12-05 04:31:17] [INFO] Начало: Загрузка данных
[2025-12-05 04:31:17] [INFO] Загружен датасет из data/processed
[2025-12-05 04:31:17] [INFO] Количество примеров: 50000
[2025-12-05 04:31:17] [INFO] Колонки датасета: ['input', 'target']
[2025-12-05 04:31:17] [INFO] Завершено: Загрузка данных | Затрачено времени: 0.01 секунд (0:00:00)
[2025-12-05 04:31:17] [INFO] Начало: Загрузка токенизатора
[2025-12-05 04:31:20] [INFO] Токенизатор загружен: google/flan-t5-small
[2025-12-05 04:31:20] [INFO] Размер словаря: 32100
[2025-12-05 04:31:20] [INFO] Завершено: Загрузка токенизатора | Затрачено времени: 3.75 секунд (0:00:03)
[2025-12-05 04:31:20] [INFO] Начало: Токенизация данных
[2025-12-05 04:31:38] [INFO] Токенизация завершена. Размер: 50000
[2025-12-05 04:31:38] [INFO] Завершено: Токенизация данных | Затрачено времени: 17.06 секунд (0:00:17)
[2025-12-05 04:31:38] [INFO] Начало: Загрузка модели
[2025-12-05 04:31:38] [INFO] Загрузка модели в 8-bit режиме...
[2025-12-05 04:32:03] [INFO] Модель подготовлена для k-bit обучения
[2025-12-05 04:32:03] [INFO] Завершено: Загрузка модели | Затрачено времени: 25.06 секунд (0:00:25)
[2025-12-05 04:32:03] [INFO] Начало: Настройка LoRA
[2025-12-05 04:32:03] [INFO] LoRA конфигурация применена
[2025-12-05 04:32:03] [INFO] Всего параметров: 79,123,840
[2025-12-05 04:32:03] [INFO] Обучаемых параметров (LoRA): 2,162,688 (2.73%)
[2025-12-05 04:32:03] [INFO] Завершено: Настройка LoRA | Затрачено времени: 0.11 секунд (0:00:00)
[2025-12-05 04:32:03] [INFO] ================================================================================
ПАРАМЕТРЫ ОБУЧЕНИЯ
================================================================================
Модель: google/flan-t5-small
Устройство: cuda
8-bit обучение: True
Размер батча: 8
Эпохи: 3
Learning rate: 0.0003
Макс. длина входных данных: 256
Макс. длина целевых данных: 128
Размер обучающего набора: 50000 примеров
Всего параметров модели: 79,123,840
Обучаемых параметров: 2,162,688 (2.73%)
Необучаемых параметров: 76,961,152
================================================================================
[2025-12-05 04:32:05] [INFO] ================================================================================
[2025-12-05 04:32:05] [INFO] НАЧАЛО ОБУЧЕНИЯ МОДЕЛИ
[2025-12-05 04:32:05] [INFO] ================================================================================
[2025-12-05 04:32:05] [INFO] Начало: Обучение модели
[2025-12-05 04:34:08] [INFO] Шаг 100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.032}
[2025-12-05 04:36:13] [INFO] Шаг 200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.064}
[2025-12-05 04:37:59] [INFO] Шаг 300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.096}
[2025-12-05 04:39:48] [INFO] Шаг 400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.128}
[2025-12-05 04:41:44] [INFO] Шаг 500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.16}
[2025-12-05 04:43:34] [INFO] Шаг 600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.192}
[2025-12-05 04:45:34] [INFO] Шаг 700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.224}
[2025-12-05 04:47:27] [INFO] Шаг 800: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.256}
[2025-12-05 04:49:14] [INFO] Шаг 900: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.288}
[2025-12-05 04:51:22] [INFO] Шаг 1000: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.32}
[2025-12-05 04:53:21] [INFO] Шаг 1100: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.352}
[2025-12-05 04:55:27] [INFO] Шаг 1200: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.384}
[2025-12-05 04:57:30] [INFO] Шаг 1300: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.416}
[2025-12-05 04:59:32] [INFO] Шаг 1400: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.448}
[2025-12-05 05:01:22] [INFO] Шаг 1500: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.48}
[2025-12-05 05:03:12] [INFO] Шаг 1600: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.512}
[2025-12-05 05:05:02] [INFO] Шаг 1700: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.544}
[2025-12-05 05:06:52] [INFO] Шаг 1800: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.576}
[2025-12-05 05:08:41] [INFO] Шаг 1900: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.608}
[2025-12-05 05:10:31] [INFO] Шаг 2000: {'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003, 'epoch': 0.64}
